{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN: K-Nearest Neighbors\n",
    "\n",
    "En este notebooks, vamos a implementar el algoritmo de clasificación de K vecinos más cercanos usando la libreria Scikit-learn. Además, vamos a evaluar los resultados obtenidos para distintos valores del hiperparámetro k (número de vecinos).\n",
    "\n",
    "## 1. Clasificación en el dataset IRIS\n",
    "\n",
    "Para comenzar, vamos a trabajar con un dataset que ya conocemos, el de IRIS.\n",
    "\n",
    "### 1.1 Cargar el dataset\n",
    "\n",
    "Primero cargamos las librerias y el dataset que vamos a usar (el cual en este caso lo traemos desde la libreria Seaborn). Separamos el dataset entre features, `X`, y labels `y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "iris = sns.load_dataset('iris')\n",
    "X = iris.drop(\"species\", axis=1)\n",
    "y = iris.species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, como aprendimos la clase anterior, vamos a separar el dataset en conjuntos de entrenamiento `X_train, y_train` y de testeo `X_test,y_test` usando la función `train_test_split` de scikit-learn (¡recordar importarla primero!). Esto lo hacemos para separar parte de los datos `X_test,y_test` con los cuales **no vamos a entrenar el dataset, y vamos a usarlos únicamente para evaluar el resultado de nuestro algoritmo**.\n",
    "\n",
    "**Ejercicio**: Separar los instancias del Dataset, tomando en las variables `X_train, y_train` un 90% para entrenamiento y en las variables `X_test,y_test` un 10% para evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Preprocesamiento de Datos\n",
    "\n",
    "Antes de implementar un algoritmo de KNN, es muy importante normalizar los datos. Veamos algunos estadisticos de los distintos Features de nuestro Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Maximos: \\n',X_train.max(),'\\n \\n Mínimas: \\n',X_train.min(),'\\n')\n",
    "print('Means: \\n',X_train.mean(),'\\n \\n Std: \\n',X_train.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, los features poseen diferentes escalas (la media de la variables *sepal_length* es 5 veces la media de la variable *petal_width*). Pasemos entonces a normalizar estos datos.\n",
    "\n",
    "**Ejercicio**: Normalizar los features del Dataset utilizando la función `StandardScaler` (que deben importar desde `sklearn.preprocessing`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvamos a analizar los mismos estadísticos luego de la transformación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Maximos: \\n',pd.DataFrame(X_train).max(),'\\n \\n Mínimas: \\n',pd.DataFrame(X_train).min(),'\\n')\n",
    "print('Means: \\n',pd.DataFrame(X_train).mean(),'\\n \\n Std: \\n',pd.DataFrame(X_train).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para pensar**:\n",
    "1. ¿Por qué será que es tan importante normalizar los datos en el caso de usar un algoritmo de KNN?\n",
    "2. Analizar los resultados de los estadísticos (Max, Min, Media y Std) después de usar la función `StandardScaler` y discutir si presentan los valores esperados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Implementar el clasificador KNN \n",
    "Vamos a importar la clase del modelo KNN desde scikit-learn usando la siguiente linea: `from sklearn.neighbors import KNeighborsClassifier`. \n",
    "\n",
    "Cuando creamos un objeto de esta clase, podemos definir el valor de algunos atributos del modelo. Estos atributos son los **hiperparámetros** que queremos utilizar. En el caso de este modelo, estos atributos van a ser la métria de la distancia (que por default es la euclideana) y, el más importante, el número de vecinos `k`. Vamos a cargar el modelo utilizando `k=2` vecinos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya estamos en condiciones de entrenar el modelo. \n",
    "\n",
    "**Ejercicio**: Entrenar el modelo con el set de entrenamiento y predecir las etiquetas tanto sobre el set de entrenamiento (train) como en el set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETAR.fit(COMPLETAR)\n",
    "\n",
    "y_train_pred = COMPLETAR\n",
    "y_test_pred = COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar el porcentaje de aciertos en la predicción de las etiquetas, vamos a utilizar la función `accuracy_score` que importamos desde `sklearn.metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print('Porcentaje de aceirtos sobre el set de entrenamiento:', train_acc)\n",
    "print('Porcentaje de aceirtos sobre el set de evaluación:',test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**:\n",
    "\n",
    "1. ¿Son estos valores de accuracy que obtuvieron satisfactorios?\n",
    "2. ¿Será el parámetro de `k=2` el mejor para elegir en nuestro modelo?¿Cómo podríamos saberlo?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Encontrar el mejor hiperparámetro\n",
    "\n",
    "Para esto, debemos evaluar el accuracy del modelo en el set de evaluación para distintos valores del parámetro `k`. Vamos entonces a repetir el esquema de: **definir, entrenar y predecir** en un loop `for` que recorre una lista con distintos valores de `k`.\n",
    "\n",
    "**Ejercicio**: Trabajar en el siguiente bloque de codigo, de manera de completar con valores las listas `lista_accuracy_train` y `lista_accuracy_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las listas vacias para los valores de accuracy deseados\n",
    "lista_accuracy_train = []\n",
    "lista_accuracy_test = []\n",
    "\n",
    "# Definimos la lista de valores de k que vamos a explorar\n",
    "k_vecinos = [1,2,3,4,5,6,7,8,9,10,15,20,25,30,35,40]\n",
    "\n",
    "# Generamos en loop sobre los distintos valores de k \n",
    "for k in k_vecinos:\n",
    "    \n",
    "    # Vamos a repetir el siguiente bloque de código\n",
    "    \n",
    "    # Definir el modelo con el valor de vecinos deseado\n",
    "    COMPLETAR\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    COMPLETAR\n",
    "    \n",
    "    # Predecir y evaluar sobre el set de entrenamiento\n",
    "    y_train_pred = COMPLETAR\n",
    "    train_acc = COMPLETAR\n",
    "    \n",
    "    # Predecir y evaluar sobre el set de evaluación\n",
    "    y_test_pred = COMPLETAR\n",
    "    test_acc = COMPLETAR\n",
    "    \n",
    "    # Agregar la información a las listas\n",
    "    lista_accuracy_train.COMPLETAR\n",
    "    lista_accuracy_test.COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**: Realizar un gráfico que muestre la curvas de accuracy en el set de entrenamiento (`lista_accuracy_train`) y accuracy en el set de entrenamiento (`lista_accuracy_test`) en función del numero de vecinos (`k_vecinos`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para pensar**:\n",
    "1. Analice los resultados de las curvas obtenidas. ¿Les parecen razonables?\n",
    "2. Para el caso de `k = 1`, donde la performance en el set de entrenamiento es mucho mayor a la performance en en set de test. ¿En que tipo de régimen diría que se encuentra el modelo? ¿Por qué?\n",
    "3. ¿Qué valor de `k` eligiría? ¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente bloque de codigo produce gráficos de la frontera de decisión para un clasificador KNN entrenado en el IRIS dataset utilizando distintos valores del hiperparámetro k. Con el fin de poder graficar los resultados, utilizamos sólo dos Features. \n",
    "\n",
    "No hace falta que modifique el código, sólo analice los gráficos producidos y vuelva a pensar las tres preguntas anteriores en términos de Underfitting y Overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "for k in [1,8,50]:\n",
    "    \n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n",
    "                edgecolor='k', s=20)\n",
    "    \n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(\"Clasificador KNN con k = %i\"% (k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
